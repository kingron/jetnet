[net]
# Testing
batch=1
subdivisions=1
# Training
#batch=64
#subdivisions=8
width=960
height=544
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 430000
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-3
activation=linear

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=relu

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=relu

[convolutional]
size=1
stride=1
pad=1
filters=33
activation=linear


[yolo]
mask = 6,7,8
anchors = 7,8,  22,19,  33,51,  70,107,  76,37,  117,200,  204,101,  238,252,  458,277
classes=6
num=9
jitter=.3
ignore_thresh = .7
ignore_region_thresh = .7
truth_thresh = 1
random=1
max=300


[route]
layers = -4

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 61



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=relu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=relu

[convolutional]
size=1
stride=1
pad=1
filters=33
activation=linear


[yolo]
mask = 3,4,5
anchors = 7,8,  22,19,  33,51,  70,107,  76,37,  117,200,  204,101,  238,252,  458,277
classes=6
num=9
jitter=.3
ignore_thresh = .7
ignore_region_thresh = .7
truth_thresh = 1
random=1
max=300



[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 36



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=relu

[convolutional]
size=1
stride=1
pad=1
filters=33
activation=linear


[yolo]
mask = 0,1,2
anchors = 7,8,  22,19,  33,51,  70,107,  76,37,  117,200,  204,101,  238,252,  458,277
classes=6
num=9
jitter=.3
ignore_thresh = .7
ignore_region_thresh = .7
truth_thresh = 1
random=1
max=300

